###GWAS using Rserve

#V3 - Sep 25- 2016 - Job was being submitted too many times
#V2 - Sep 20 - 2016 - Now set up to run as array jobs, compatible with LISA

##Pre-requisites (R packages)

#module load c/intel
#module load fortran/intel
#module load intel-studio/2015.2
#module load R

#R
#install.packages('VGAM')
#install.packages('Rserve')
#TO THE USER:pick a mirror!
#q('no')


##User modifiable settings

#Write working directory (default to present directory)
 WORKING_DIR=
 cd $WORKING_DIR

 export OMP_NUM_THREADS=1

#Write a study name abbreviation
 abbr=

#Set node size (default 16) - On LISA the whole node is yours no matter what, so we can ignore this and just assume 16.
 nodesize=16

#Supply folder name of genotype data (use the full file path)
 bgn_folder=

#Give path to a .fam file for constructing the phenotype sheet (the .fam files generated by ricopili should be identical. Pick an arbitrary one)
 famfile=

#Supply phenotypes, covariates
 phenotype_file_path=
 covar_file_path=

#Supply regression code (Formatted for Rserve). Default is ordered logit
 regression_file=ologit_rserve_v1_may25_2016.R

#Name of the phenotype you would like to use in the analysis
 phenotype=
#Supply exact names of covariates as a quoted, comma delimted list (no blank spaces
 covariates=

## User shouldn't need to modify below settings (

#List of all genotype data to be analyzed (Just a list of folder contents)
 cd $WORKING_DIR
 ls $bgn_folder | grep .bim | sed 's/.bim//g' > pts_"$abbr".tobe_analyzed

#Makes some extra folders
 if [ ! -d "temporary_files" ] ; then mkdir temporary_files; fi;
 if [ ! -d "errandout" ]; then mkdir errandout; fi;

#Load R module (LISA) 
 module load R 
#Make a phenotype file 
 Rscript make_phenotype_file_v2_sep19_2016.R $famfile $phenotype_file_path $phenotype 0
#Make a covariate file
 Rscript make_phenotype_file_v2_sep19_2016.R $famfile $covar_file_path $covariates 1

#Construct the job code. 

#Write a PLINK command for every file specified to be analyzed
 if [ ! -d "plink_assoc_"$abbr"_"$phenotype"" ]; then mkdir plink_assoc_"$abbr"_"$phenotype"; fi;

 echo -n "" > temporary_files/"$abbr"_"$phenotype"_analyses.plink_commands

IFS=$'\n'
for file_name in $(cat pts_"$abbr".tobe_analyzed) 
do
 #MUST USE PLINK1 - RPlink not yet stable for PLINK2
 echo "/home/sdalvie/PGC_PTSD/trauma_GWAS/analysis/plink --noweb --memory 3000 --bfile "$bgn_folder"/"$file_name" --out plink_assoc_"$abbr"_"$phenotype"/"$abbr"_"$phenotype"_"$file_name".regression --pheno "$phenotype_file_path".pheno_use  --geno 0.02 --covar "$covar_file_path".covar_use --maf 0.005 --R $regression_file" >> temporary_files/"$abbr"_"$phenotype"_analyses.plink_commands
done

#Calculate total number of commands 
 ncommands=$(wc -l temporary_files/"$abbr"_"$phenotype"_analyses.plink_commands | awk '{print $1}' )

#Make a job code, where 'nodesize' processes will run on each node simultaneously
 nodeuse=$nodesize   ##$(($nodesize / 2))

#Total number of jobs = Number of commands / number of commands used per job, rounded up 
 totjobs=$(( ($ncommands + $nodeuse - 1 ) / $nodeuse ))
 echo "Will run $ncommands commands over $totjobs jobs, assuming $nodeuse cores available per node with $nodesize cores"


 echo "Submitting job"
 ##qsub  trauma_analysis_v1.pbs -e errandout/"$abbr"_"$phenotype"_"$file_name".e -o errandout/"$abbr"_"$phenotype"_"$file_name".o -t 1-$totjobs -d $WORKING_DIR -lnodes=1:cores$nodesize -V -lwalltime=00:05:00 -F "-n $nodeuse -o "$abbr"_"$phenotype""

sbatch -a 1-$totjobs --error errandout/"$abbr"_"$phenotype"_"$file_name".e --output errandout/"$abbr"_"$phenotype"_"$file_name".o -D $WORKING_DIR -t 83:05:00 --export=outputfile="$abbr"_"$phenotype" trauma_analysis_v1_slurm.pbs




